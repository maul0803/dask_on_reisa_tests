slurmstepd: info: Setting TMPDIR to /scratch/10899143. Previous errors about TMPDIR can be discarded
Slurm job started at 07/03/2025_10:34:00 AM

In transit.
Initing Ray (1 head node + 4 worker nodes + 4 simulation nodes) on nodes: 
	ilk-241 ilk-242 ilk-243 ilk-244 ilk-245 ilk-246 ilk-247 ilk-248 ilk-249
Head node: 172.30.211.14:6379


RAY_DEPLOY_TIME:     23.49216
2025-03-07 10:34:28,291	INFO packaging.py:520 -- Creating a file package for local directory '/mnt/lustre/scratch/nlsas/home/ulc/cursos/curso341/dask_on_reisa_tests/E1/DASK_ON_REISA_ONE_ACTOR/derivative/P8-SN4-LS536-GS4294-I10-AN4-D2025-03-07_09-35-54'.
2025-03-07 10:34:28,318	INFO packaging.py:347 -- Pushing file package 'gcs://_ray_pkg_483c7c8cfcead331.zip' (0.48MiB) to Ray cluster...
2025-03-07 10:34:28,325	INFO packaging.py:360 -- Successfully pushed file package 'gcs://_ray_pkg_483c7c8cfcead331.zip'.
RAY_INIT_TIME:       4.62862
Iter [0]
Iter [1]
Iter [2]
Iter [3]
Iter [4]
Iter [5]
Iter [6]
Iter [7]
Iter [8]
Iter [9]
GLOBAL_PUT_TIME:     8.642053842544556 (avg:0.86421)
ACTOR_CONCURRENCY:   8
SIMULATION_TIME:     72.807605920000000 (avg: 7.280760592000000)
SIM_WTHOUT_PDI:      47.341840980000008 (avg: 4.734184098000001)
PDI_DELAY:           25.465764939999993 (avg: 2.546576493999999)

GLOBAL_SIZE_(GiB):   4194304
LOCAL_SIZE_(MiB):    512
ITERATIONS:          10

MPI_PER_NODE:        2
MPI_PARALLELISM:     8

WORKER_NODES:        4
CPUS_PER_WORKER:     64
WORKER_PARALLELISM:  256


SLURM_JOB_ID:        10899143
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 10899143 ON ilk-241 CANCELLED AT 2025-03-07T10:54:02 DUE TO TIME LIMIT ***
slurmstepd: error: *** STEP 10899143.10 ON ilk-242 CANCELLED AT 2025-03-07T10:54:02 DUE TO TIME LIMIT ***
