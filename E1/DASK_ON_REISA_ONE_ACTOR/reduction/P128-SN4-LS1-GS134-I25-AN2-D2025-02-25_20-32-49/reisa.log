slurmstepd: info: Setting TMPDIR to /scratch/10772548. Previous errors about TMPDIR can be discarded
Slurm job started at 26/02/2025_12:32:38 AM

In transit.
Initing Ray (1 head node + 2 worker nodes + 4 simulation nodes) on nodes: 
	ilk-172 ilk-173 ilk-177 ilk-178 ilk-179 ilk-183 ilk-185
Head node: 172.30.204.28:6379


RAY_DEPLOY_TIME:     24.33134
2025-02-26 00:33:07,368	INFO packaging.py:520 -- Creating a file package for local directory '/mnt/lustre/scratch/nlsas/home/ulc/cursos/curso341/dask_on_reisa_tests/E1/DASK_ON_REISA_ONE_ACTOR/reduction/P128-SN4-LS1-GS134-I25-AN2-D2025-02-25_20-32-49'.
2025-02-26 00:33:07,393	INFO packaging.py:347 -- Pushing file package 'gcs://_ray_pkg_26c1d2a9a24853a2.zip' (0.48MiB) to Ray cluster...
2025-02-26 00:33:07,399	INFO packaging.py:360 -- Successfully pushed file package 'gcs://_ray_pkg_26c1d2a9a24853a2.zip'.
RAY_INIT_TIME:       5.80509
Iter [0]
Iter [2]
Iter [4]
Iter [6]
Iter [8]
Iter [10]
Iter [12]
Iter [14]
Iter [16]
Iter [18]
Iter [20]
Iter [22]
Iter [24]
GLOBAL_PUT_TIME:     10.06766390800476 (avg:0.40271)
ACTOR_CONCURRENCY:   8
SIMULATION_TIME:     87.965646805999995 (avg: 3.518625872240000)
SIM_WTHOUT_PDI:      31.225368528999986 (avg: 1.249014741159999)
PDI_DELAY:           56.740278277000009 (avg: 2.269611131080000)

GLOBAL_SIZE_(GiB):   131072
LOCAL_SIZE_(MiB):    1
ITERATIONS:          25

MPI_PER_NODE:        32
MPI_PARALLELISM:     128

WORKER_NODES:        2
CPUS_PER_WORKER:     30
WORKER_PARALLELISM:  60


SLURM_JOB_ID:        10772548
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 10772548.8 ON ilk-173 CANCELLED AT 2025-02-26T00:52:44 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 10772548 ON ilk-172 CANCELLED AT 2025-02-26T00:52:44 DUE TO TIME LIMIT ***
