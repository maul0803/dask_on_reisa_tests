slurmstepd: info: Setting TMPDIR to /scratch/10772502. Previous errors about TMPDIR can be discarded
Slurm job started at 25/02/2025_09:24:14 PM

In transit.
Initing Ray (1 head node + 2 worker nodes + 4 simulation nodes) on nodes: 
	ilk-59 ilk-65 ilk-67 ilk-68 ilk-91 ilk-146 ilk-224
Head node: 172.30.202.11:6379


RAY_DEPLOY_TIME:     22.69632
2025-02-25 21:24:42,449	INFO packaging.py:520 -- Creating a file package for local directory '/mnt/lustre/scratch/nlsas/home/ulc/cursos/curso341/dask_on_reisa_tests/E1/DASK_ON_REISA/derivative/P128-SN4-LS1-GS134-I12-AN2-D2025-02-25_20-31-07'.
2025-02-25 21:24:42,475	INFO packaging.py:347 -- Pushing file package 'gcs://_ray_pkg_d47b77283a1f67f7.zip' (0.48MiB) to Ray cluster...
2025-02-25 21:24:42,482	INFO packaging.py:360 -- Successfully pushed file package 'gcs://_ray_pkg_d47b77283a1f67f7.zip'.
RAY_INIT_TIME:       7.96316
Iter [0]
Iter [1]
Iter [2]
Iter [3]
Iter [4]
Iter [5]
Iter [6]
Iter [7]
Iter [8]
Iter [9]
Iter [10]
Iter [11]
GLOBAL_PUT_TIME:     0.08227396011352539 (avg:0.00686)
ACTOR_CONCURRENCY:   8
[2m[36m(process_task pid=512889, ip=10.120.202.19)[0m gt: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=512823, ip=10.120.202.19)[0m result: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=512823, ip=10.120.202.19)[0m result_dask: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=3574391, ip=10.120.202.17)[0m gt: <class 'dask.array.core.Array'>[32m [repeated 93x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[2m[36m(process_task pid=3574391, ip=10.120.202.17)[0m result: <class 'dask.array.core.Array'>[32m [repeated 93x across cluster][0m
[2m[36m(process_task pid=3574809, ip=10.120.202.17)[0m result_dask: <class 'dask.array.core.Array'>[32m [repeated 93x across cluster][0m
[2m[36m(process_task pid=512824, ip=10.120.202.19)[0m gt: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=512824, ip=10.120.202.19)[0m result: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=512824, ip=10.120.202.19)[0m result_dask: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=514366, ip=10.120.202.19)[0m gt: <class 'dask.array.core.Array'>[32m [repeated 101x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[2m[36m(process_task pid=514366, ip=10.120.202.19)[0m result: <class 'dask.array.core.Array'>[32m [repeated 101x across cluster][0m
[2m[36m(process_task pid=514366, ip=10.120.202.19)[0m result_dask: <class 'dask.array.core.Array'>[32m [repeated 101x across cluster][0m
[2m[36m(process_task pid=512890, ip=10.120.202.19)[0m gt: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=512890, ip=10.120.202.19)[0m result: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=512890, ip=10.120.202.19)[0m result_dask: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=512890, ip=10.120.202.19)[0m gt: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=512890, ip=10.120.202.19)[0m result: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=512890, ip=10.120.202.19)[0m result_dask: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=512890, ip=10.120.202.19)[0m gt: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=512890, ip=10.120.202.19)[0m result: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=512890, ip=10.120.202.19)[0m result_dask: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=514524, ip=10.120.202.19)[0m gt: <class 'dask.array.core.Array'>[32m [repeated 90x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[2m[36m(process_task pid=514416, ip=10.120.202.19)[0m result: <class 'dask.array.core.Array'>[32m [repeated 88x across cluster][0m
[2m[36m(process_task pid=514920, ip=10.120.202.19)[0m result_dask: <class 'dask.array.core.Array'>[32m [repeated 88x across cluster][0m
[2m[36m(process_task pid=512822, ip=10.120.202.19)[0m gt: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=512822, ip=10.120.202.19)[0m result: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=512822, ip=10.120.202.19)[0m result_dask: <class 'dask.array.core.Array'>
[2m[36m(process_task pid=514442, ip=10.120.202.19)[0m gt: <class 'dask.array.core.Array'>[32m [repeated 95x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[2m[36m(process_task pid=514442, ip=10.120.202.19)[0m result: <class 'dask.array.core.Array'>[32m [repeated 95x across cluster][0m
[2m[36m(process_task pid=514442, ip=10.120.202.19)[0m result_dask: <class 'dask.array.core.Array'>[32m [repeated 95x across cluster][0m
SIMULATION_TIME:     9.068788114999998 (avg: 0.755732342916667)
SIM_WTHOUT_PDI:      3.186484113999999 (avg: 0.265540342833333)
PDI_DELAY:           5.882304001000000 (avg: 0.490192000083333)

GLOBAL_SIZE_(GiB):   131072
LOCAL_SIZE_(MiB):    1
ITERATIONS:          12

MPI_PER_NODE:        32
MPI_PARALLELISM:     128

WORKER_NODES:        2
CPUS_PER_WORKER:     30
WORKER_PARALLELISM:  60


SLURM_JOB_ID:        10772502
EST_ANALYTICS_TIME:  33.17514 (avg:2.76460)

Slurm job finished at 25/02/2025_09:25:22 PM

*****************************************************************************
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 10772502)                   *
*                                                                           *
*****************************************************************************

Job ID: 10772502
Cluster: finisterrae3
User/Group: curso341/ulc
State: COMPLETED (exit code 0)
Nodes: 7
Cores per node: 40
CPU Utilized: 00:18:33
CPU Efficiency: 5.68% of 05:26:40 core-walltime
Job Wall-clock time: 00:01:10
Memory Utilized: 484.92 MB
Memory Efficiency: 0.04% of 1.09 TB

 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 ++ It seems that you do not need that much memory so we recommend        ++
 ++ requesting less memory in other similar jobs.                         ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 
*****************************************************************************


*****************************************************************************
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 10772502)                   *
*                                                                           *
*****************************************************************************

Job ID: 10772502
Cluster: finisterrae3
User/Group: curso341/ulc
State: COMPLETED (exit code 0)
Nodes: 7
Cores per node: 40
CPU Utilized: 00:18:33
CPU Efficiency: 5.68% of 05:26:40 core-walltime
Job Wall-clock time: 00:01:10
Memory Utilized: 484.92 MB
Memory Efficiency: 0.04% of 1.09 TB

 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 ++ It seems that you do not need that much memory so we recommend        ++
 ++ requesting less memory in other similar jobs.                         ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 
*****************************************************************************


*****************************************************************************
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 10772502)                   *
*                                                                           *
*****************************************************************************

Job ID: 10772502
Cluster: finisterrae3
User/Group: curso341/ulc
State: COMPLETED (exit code 0)
Nodes: 7
Cores per node: 40
CPU Utilized: 00:18:33
CPU Efficiency: 5.68% of 05:26:40 core-walltime
Job Wall-clock time: 00:01:10
Memory Utilized: 484.92 MB
Memory Efficiency: 0.04% of 1.09 TB

 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 ++ It seems that you do not need that much memory so we recommend        ++
 ++ requesting less memory in other similar jobs.                         ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 
*****************************************************************************


*****************************************************************************
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 10772502)                   *
*                                                                           *
*****************************************************************************

Job ID: 10772502
Cluster: finisterrae3
User/Group: curso341/ulc
State: COMPLETED (exit code 0)
Nodes: 7
Cores per node: 40
CPU Utilized: 00:18:33
CPU Efficiency: 5.68% of 05:26:40 core-walltime
Job Wall-clock time: 00:01:10
Memory Utilized: 484.92 MB
Memory Efficiency: 0.04% of 1.09 TB

 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 ++ It seems that you do not need that much memory so we recommend        ++
 ++ requesting less memory in other similar jobs.                         ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 
*****************************************************************************


*****************************************************************************
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 10772502)                   *
*                                                                           *
*****************************************************************************

Job ID: 10772502
Cluster: finisterrae3
User/Group: curso341/ulc
State: COMPLETED (exit code 0)
Nodes: 7
Cores per node: 40
CPU Utilized: 00:40:57
CPU Efficiency: 12.54% of 05:26:40 core-walltime
Job Wall-clock time: 00:01:10
Memory Utilized: 4.08 GB
Memory Efficiency: 0.36% of 1.09 TB

 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 ++ It seems that you do not need that much memory so we recommend        ++
 ++ requesting less memory in other similar jobs.                         ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 
*****************************************************************************


*****************************************************************************
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 10772502)                   *
*                                                                           *
*****************************************************************************

Job ID: 10772502
Cluster: finisterrae3
User/Group: curso341/ulc
State: COMPLETED (exit code 0)
Nodes: 7
Cores per node: 40
CPU Utilized: 00:40:57
CPU Efficiency: 12.54% of 05:26:40 core-walltime
Job Wall-clock time: 00:01:10
Memory Utilized: 4.08 GB
Memory Efficiency: 0.36% of 1.09 TB

 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 ++ It seems that you do not need that much memory so we recommend        ++
 ++ requesting less memory in other similar jobs.                         ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 
*****************************************************************************


*****************************************************************************
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 10772502)                   *
*                                                                           *
*****************************************************************************

Job ID: 10772502
Cluster: finisterrae3
User/Group: curso341/ulc
State: COMPLETED (exit code 0)
Nodes: 7
Cores per node: 40
CPU Utilized: 00:42:49
CPU Efficiency: 13.11% of 05:26:40 core-walltime
Job Wall-clock time: 00:01:10
Memory Utilized: 4.08 GB
Memory Efficiency: 0.36% of 1.09 TB

 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 ++ It seems that you do not need that much memory so we recommend        ++
 ++ requesting less memory in other similar jobs.                         ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 
*****************************************************************************

