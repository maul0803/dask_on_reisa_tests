slurmstepd: info: Setting TMPDIR to /scratch/10932531. Previous errors about TMPDIR can be discarded
Slurm job started at 10/03/2025_06:48:07 PM

In transit.
Initing Ray (1 head node + 2 worker nodes + 4 simulation nodes) on nodes: 
	ilk-119 ilk-120 ilk-121 ilk-122 ilk-180 ilk-181 ilk-252
Head node: 172.30.203.23:6379


RAY_DEPLOY_TIME:     24.16805
RAY_INIT_TIME:       3.63056
Iter [0]
Iter [1]
Iter [2]
Iter [3]
Iter [4]
2025-03-10 18:48:40,720	INFO packaging.py:520 -- Creating a file package for local directory '/mnt/lustre/scratch/nlsas/home/ulc/cursos/curso341/dask_on_reisa_tests/E5/REISA/derivative/P128-SN4-LS1-GS134-I10-AN2-D2025-03-10_18-34-58'.
Iter [5]
Iter [6]
Iter [7]
Iter [8]
Iter [9]
GLOBAL_PUT_TIME:     0.030156373977661133 (avg:0.00302)
ACTOR_CONCURRENCY:   8
SIMULATION_TIME:     5.221466880000000 (avg: 0.522146688000000)
SIM_WTHOUT_PDI:      3.080666012999998 (avg: 0.308066601300000)
PDI_DELAY:           2.140800867000002 (avg: 0.214080086700000)

GLOBAL_SIZE_(GiB):   131072
LOCAL_SIZE_(MiB):    1
ITERATIONS:          10

MPI_PER_NODE:        32
MPI_PARALLELISM:     128

WORKER_NODES:        2
CPUS_PER_WORKER:     64
WORKER_PARALLELISM:  128


SLURM_JOB_ID:        10932531
2025-03-10 18:48:47,937	INFO packaging.py:347 -- Pushing file package 'gcs://_ray_pkg_289c8a4d769b6ca5.zip' (0.48MiB) to Ray cluster...
2025-03-10 18:48:47,944	INFO packaging.py:360 -- Successfully pushed file package 'gcs://_ray_pkg_289c8a4d769b6ca5.zip'.
EST_ANALYTICS_TIME:  610.27470 (avg:61.02747)
Traceback (most recent call last):
  File "/mnt/lustre/scratch/nlsas/home/ulc/cursos/curso341/dask_on_reisa_tests/E5/REISA/derivative/P128-SN4-LS1-GS134-I10-AN2-D2025-03-10_18-34-58/derivative.py", line 65, in <module>
    result = handler.get_result(process_func, iter_func, global_func=global_func, selected_iters=iterations, kept_iters=5, timeline=False)
  File "/mnt/lustre/scratch/nlsas/home/ulc/cursos/curso341/dask_on_reisa_tests/E5/REISA/derivative/P128-SN4-LS1-GS134-I10-AN2-D2025-03-10_18-34-58/reisa.py", line 156, in get_result
    return global_func(RayList(results))
  File "/mnt/lustre/scratch/nlsas/home/ulc/cursos/curso341/dask_on_reisa_tests/E5/REISA/derivative/P128-SN4-LS1-GS134-I10-AN2-D2025-03-10_18-34-58/derivative.py", line 58, in global_func
    return np.average(final_results[:])
  File "/mnt/lustre/scratch/nlsas/home/ulc/cursos/curso341/dask_on_reisa_tests/E5/REISA/derivative/P128-SN4-LS1-GS134-I10-AN2-D2025-03-10_18-34-58/reisa.py", line 50, in __getitem__
    return ray.get(RayList(item))
  File "/home/ulc/cursos/curso341/.local/lib/python3.9/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return getattr(ray, func.__name__)(*args, **kwargs)
  File "/home/ulc/cursos/curso341/.local/lib/python3.9/site-packages/ray/util/client/api.py", line 42, in get
    return self.worker.get(vals, timeout=timeout)
  File "/home/ulc/cursos/curso341/.local/lib/python3.9/site-packages/ray/util/client/worker.py", line 434, in get
    res = self._get(to_get, op_timeout)
  File "/home/ulc/cursos/curso341/.local/lib/python3.9/site-packages/ray/util/client/worker.py", line 462, in _get
    raise err
ray.exceptions.RayTaskError: [36mray::iter_task()[39m (pid=1068449, ip=172.30.203.24)
  File "/mnt/lustre/scratch/nlsas/home/ulc/cursos/curso341/dask_on_reisa_tests/E5/REISA/derivative/P128-SN4-LS1-GS134-I10-AN2-D2025-03-10_18-34-58/reisa.py", line 146, in iter_task
    return iter_func(i, RayList(itertools.chain.from_iterable(current_results)))
  File "/mnt/lustre/scratch/nlsas/home/ulc/cursos/curso341/dask_on_reisa_tests/E5/REISA/derivative/P128-SN4-LS1-GS134-I10-AN2-D2025-03-10_18-34-58/derivative.py", line 48, in iter_func
    return np.average(current_results[:])
  File "/scratch/10932531/ray/session_2025-03-10_18-48-10_112833_2452032/runtime_resources/working_dir_files/_ray_pkg_289c8a4d769b6ca5/reisa.py", line 50, in __getitem__
    return ray.get(RayList(item))
ray.exceptions.RayTaskError: [36mray::process_task()[39m (pid=1069104, ip=172.30.203.24)
  File "/mnt/lustre/scratch/nlsas/home/ulc/cursos/curso341/dask_on_reisa_tests/E5/REISA/derivative/P128-SN4-LS1-GS134-I10-AN2-D2025-03-10_18-34-58/reisa.py", line 127, in process_task
    return process_func(rank, i, queue)
  File "/mnt/lustre/scratch/nlsas/home/ulc/cursos/curso341/dask_on_reisa_tests/E5/REISA/derivative/P128-SN4-LS1-GS134-I10-AN2-D2025-03-10_18-34-58/derivative.py", line 35, in process_func
    gt = np.array(queue[-5:])
  File "/mnt/lustre/scratch/nlsas/home/ulc/cursos/curso341/dask_on_reisa_tests/E5/REISA/derivative/P128-SN4-LS1-GS134-I10-AN2-D2025-03-10_18-34-58/reisa.py", line 50, in __getitem__
    return ray.get(RayList(item))
ray.exceptions.ObjectFetchTimedOutError: Failed to retrieve object 00ffffffffffffffffffffffffffffffffffffff5500000004000000. To see information about where this ObjectRef was created in Python, set the environment variable RAY_record_ref_creation_sites=1 during `ray start` and `ray.init()`.

Fetch for object 00ffffffffffffffffffffffffffffffffffffff5500000004000000 timed out because no locations were found for the object. This may indicate a system-level bug.
srun: error: ilk-120: task 0: Exited with exit code 1
srun: launch/slurm: _step_signal: Terminating StepId=10932531.8

Slurm job finished at 10/03/2025_06:59:02 PM

*****************************************************************************
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 10932531)                   *
*                                                                           *
*****************************************************************************

Job ID: 10932531
Cluster: finisterrae3
User/Group: curso341/ulc
State: COMPLETED (exit code 0)
Nodes: 7
Cores per node: 64
CPU Utilized: 00:20:07
CPU Efficiency: 0.41% of 3-09:38:08 core-walltime
Job Wall-clock time: 00:10:56
Memory Utilized: 2.96 GB
Memory Efficiency: 0.19% of 1.48 TB

 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 ++ It seems that you do not need that much memory so we recommend        ++
 ++ requesting less memory in other similar jobs.                         ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 
*****************************************************************************




*****************************************************************************

*****************************************************************************
*****************************************************************************
*                                                                           *
*****************************************************************************
*                                                                           *
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 10932531)                   *

*                                                                           *

*                    JOB EFFICIENCY REPORT (seff 10932531)                   *
*                    JOB EFFICIENCY REPORT (seff 10932531)                   *
*                                                                           *
*****************************************************************************
*                    JOB EFFICIENCY REPORT (seff 10932531)                   *
*****************************************************************************
*                                                                           *
*                                                                           *
*****************************************************************************
*                                                                           *
*                                                                           *
*                                                                           *
*****************************************************************************
*****************************************************************************

*                    JOB EFFICIENCY REPORT (seff 10932531)                   *
*****************************************************************************
*                    JOB EFFICIENCY REPORT (seff 10932531)                   *


Job ID: 10932531
*                                                                           *

*                                                                           *
Job ID: 10932531
Job ID: 10932531
Cluster: finisterrae3
*****************************************************************************
Job ID: 10932531
*****************************************************************************
Cluster: finisterrae3
Cluster: finisterrae3
User/Group: curso341/ulc

Cluster: finisterrae3

User/Group: curso341/ulc
User/Group: curso341/ulc
State: COMPLETED (exit code 0)
Job ID: 10932531
User/Group: curso341/ulc
Job ID: 10932531
State: COMPLETED (exit code 0)
State: COMPLETED (exit code 0)
Nodes: 7
Cluster: finisterrae3
State: COMPLETED (exit code 0)
Cluster: finisterrae3
Nodes: 7
Nodes: 7
Cores per node: 64
User/Group: curso341/ulc
Nodes: 7
User/Group: curso341/ulc
Cores per node: 64
Cores per node: 64
CPU Utilized: 00:21:03
State: COMPLETED (exit code 0)
Cores per node: 64
State: COMPLETED (exit code 0)
CPU Utilized: 00:21:03
CPU Utilized: 00:21:03
CPU Efficiency: 0.43% of 3-09:38:08 core-walltime
Nodes: 7
CPU Utilized: 00:21:03
Nodes: 7
CPU Efficiency: 0.43% of 3-09:38:08 core-walltime
CPU Efficiency: 0.43% of 3-09:38:08 core-walltime
Job Wall-clock time: 00:10:56
Cores per node: 64
CPU Efficiency: 0.43% of 3-09:38:08 core-walltime
Cores per node: 64
Job Wall-clock time: 00:10:56
Job Wall-clock time: 00:10:56
Memory Utilized: 2.96 GB
CPU Utilized: 00:21:35
Job Wall-clock time: 00:10:56
CPU Utilized: 00:21:03
Memory Utilized: 2.96 GB
Memory Utilized: 2.96 GB
Memory Efficiency: 0.19% of 1.48 TB
CPU Efficiency: 0.44% of 3-09:38:08 core-walltime
Memory Utilized: 2.96 GB
CPU Efficiency: 0.43% of 3-09:38:08 core-walltime
Memory Efficiency: 0.19% of 1.48 TB
Memory Efficiency: 0.19% of 1.48 TB

Job Wall-clock time: 00:10:56
Memory Efficiency: 0.19% of 1.48 TB
Job Wall-clock time: 00:10:56


 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Memory Utilized: 2.96 GB

Memory Utilized: 2.96 GB
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
Memory Efficiency: 0.19% of 1.48 TB
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Memory Efficiency: 0.19% of 1.48 TB
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 ++ It seems that you do not need that much memory so we recommend        ++

 ++   Memory Efficiency is too small. Please review the requested memory. ++

 ++ It seems that you do not need that much memory so we recommend        ++
 ++ It seems that you do not need that much memory so we recommend        ++
 ++ requesting less memory in other similar jobs.                         ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++ It seems that you do not need that much memory so we recommend        ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++ requesting less memory in other similar jobs.                         ++
 ++ requesting less memory in other similar jobs.                         ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 ++ requesting less memory in other similar jobs.                         ++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 
 ++ It seems that you do not need that much memory so we recommend        ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++ It seems that you do not need that much memory so we recommend        ++
 
 
*****************************************************************************
 ++ requesting less memory in other similar jobs.                         ++
 
 ++ requesting less memory in other similar jobs.                         ++
*****************************************************************************
*****************************************************************************

 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
*****************************************************************************
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


 

 
*****************************************************************************
*****************************************************************************


